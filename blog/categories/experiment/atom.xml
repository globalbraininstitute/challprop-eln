<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Experiment | Electronic Laboratory Notebook]]></title>
  <link href="http://vveitas.github.io/blog/categories/experiment/atom.xml" rel="self"/>
  <link href="http://vveitas.github.io/"/>
  <updated>2014-12-23T13:55:43+01:00</updated>
  <id>http://vveitas.github.io/</id>
  <author>
    <name><![CDATA[vveitas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Experiment 2: 10k Agents / 100 Generations]]></title>
    <link href="http://vveitas.github.io/blog/2014/12/09/experiment-2-10k-agents-slash-100-generations/"/>
    <updated>2014-12-09T16:37:43+01:00</updated>
    <id>http://vveitas.github.io/blog/2014/12/09/experiment-2-10k-agents-slash-100-generations</id>
    <content type="html"><![CDATA[<h1 id="experimental-setup">Experimental setup:</h1>

<p>I am repeating Evo’s original experiment with <a href="https://bitbucket.org/evob/chalprop_matlab">chalprop-matlab</a> and presented in GBI seminar which is available <a href="http://ecco.vub.ac.be/?q=node/209">here</a>. The main goal of performing experiments with challprop-java is to observe the self-organization of the network defined in <a href="http://pespmc1.vub.ac.be/Papers/ChallengePropagation.pdf">this paper</a> and test hypotheses formulated there.</p>

<p>Experiment version (<a href="https://bitbucket.org/gbi/challprop-experiments">challprop-experiments</a>): fecb9bd<br />
Simulation version of experiment (<a href="https://bitbucket.org/gbi/challprop">challprop-java</a>): 0f1bdd2 <br />
(use <code>git checkout $commit$</code> if needed)</p>

<h1 id="analyses">Analyses:</h1>

<p>Quite a few things can be checked on the data generated by the simulation. I perform a related analysis for each of them and report results in separate blog posts:</p>

<p><a href="/blog/2014/12/16/analysis-2-slash-1-basic-statistics/">Analysis #2/1: benefit increase</a> (does not look good imho…)</p>

<p><a href="/blog/2014/12/19/analysis-2-slash-2-distribution-of-original-challenges/">Analysis #2/2: distribution of original challenges</a> </p>

<p><a href="/blog/2014/12/21/analysis-2-slash-3-distribution-of-link-weights/">Analysis #2/3: distribution of link weights</a> </p>

<p><a href="/blog/2014/12/23/analysis-2-slash-4-degree-distribution/">Analysis #2/4: degree distribution</a> </p>

<p><a href="">Analysis #2/..: degree/weight/benefit correlation</a> (comming soon)</p>

<p><a href="">Analysis #2/..: dynamics of link weights</a> (comming later - or maybe for the next experiment)</p>

<p><a href="">Analysis #2/..: relaxation</a> (comming even later…)</p>

<h1 id="full-list-of-simulations-parameters">Full list of simulation’s parameters:</h1>
<p>This is a long list mainly for the reference..</p>

<pre><code>## $graphDatabase
## [1] &quot;TitanCassandraLocal&quot;
## 
## $gephiVisualization
## [1] &quot;false&quot;
## 
## $useDatabaseOfVectors
## [1] &quot;true&quot;
## 
## $useDatabaseOfMatrixes
## [1] &quot;true&quot;
## 
## $rivalComponents
## [1] &quot;[0, 1, 2, 3, 4]&quot;
## 
## $cstSituation
## [1] &quot;0.05&quot;
## 
## $densityVectorSituation
## [1] &quot;0.25&quot;
## 
## $percnegSituation
## [1] &quot;0.2&quot;
## 
## $exponentSituation
## [1] &quot;2&quot;
## 
## $numberOfAgents
## [1] &quot;10000&quot;
## 
## $decayFactor
## [1] &quot;1&quot;
## 
## $decayRate
## [1] &quot;0.03&quot;
## 
## $reciprocityRate
## [1] &quot;0.2&quot;
## 
## $weightImportance
## [1] &quot;0.2&quot;
## 
## $believe
## [1] &quot;0.2&quot;
## 
## $propagateRate
## [1] &quot;0.4&quot;
## 
## $dimensions
## [1] &quot;10&quot;
## 
## $densityMatrix
## [1] &quot;0.5&quot;
## 
## $rfactor
## [1] &quot;0.5&quot;
## 
## $numberOfCycles
## [1] &quot;100&quot;
## 
## $newSituationsPerCycle
## [1] &quot;5&quot;
## 
## $learningRate
## [1] &quot;0.1&quot;
## 
## $randomJump
## [1] &quot;99&quot;
## 
## $propagationThreshold
## [1] &quot;0&quot;
## 
## $disableRandomJump
## [1] &quot;false&quot;
## 
## $maxBranchingFactor
## [1] &quot;1000&quot;
## 
## $respectKnowsLinksWeights
## [1] &quot;true&quot;
## 
## $bufferSize
## [1] &quot;10&quot;
## 
## $ignoreNonRivalCorrection
## [1] &quot;false&quot;
## 
## $cstNeed
## [1] &quot;0.05&quot;
## 
## $densityVectorNeed
## [1] &quot;0.5&quot;
## 
## $percnegNeed
## [1] &quot;0.5&quot;
## 
## $exponentNeed
## [1] &quot;2&quot;
## 
## $simulationStartWall
## [1] &quot;29423091026692&quot;
## 
## $simulationStartCPU
## [1] &quot;1036002841&quot;
## 
## $simulationFinishWall
## [1] &quot;53857285173308&quot;
## 
## $simulationFinishCPU
## [1] &quot;13135435550944&quot;
## 
## $archivingFinishedWall
## [1] &quot;54718185250031&quot;
## 
## $archivingFinishedCPU
## [1] &quot;13414696410662&quot;
## 
## $deletingCassandraWall
## [1] &quot;54718201348112&quot;
## 
## $deletingCassandraCPU
## [1] &quot;13414709258233&quot;</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Experiment 1: Two Predefined Clusters of Agents]]></title>
    <link href="http://vveitas.github.io/blog/2014/11/04/experiment-1-two-predefined-clusters-of-agents/"/>
    <updated>2014-11-04T18:12:20+01:00</updated>
    <id>http://vveitas.github.io/blog/2014/11/04/experiment-1-two-predefined-clusters-of-agents</id>
    <content type="html"><![CDATA[<h1 id="experimental-setup">Experimental setup:</h1>

<p>We define two clusters of agents with different need vectors. First cluster of 20 agents (C1) is initialized with all vector components equal to number 100.0. The second cluster of 20 agents (C2) is initialized with all components equal to 1.0. Processing matrices of agents in both clusters are generated by Evo’s algorithm. Full list of simulation parameters is given at the end of this page.</p>

<p>The initialized network is bombarded with randomly (well, according to Evo’s algorithm) generated situations (100) and then results are analyzed. It is expected that the benefit accomulation of agents in defferent clusters will follow diferent pattern because of C1 cluster with refuse many challenges, while C2 agents will process almost everything.</p>

<h1 id="results">Results:</h1>

<p>The results are as predicted, therefore we can conclude that the framework works correcty in this respect. The total average benefit of all agents rises monotonicly through the whole simulation and results in 3691.76, but C1 agents on average get more penalized than benefitted from challenges, therefore their average benefit at the end of simulation is negative, while average benefit of C2 agents is much higher (check analysis data).</p>

<h1 id="analysis">Analysis</h1>

<p>This experiment has only one analysis:
<a href="/blog/2014/11/04/analysis-1-slash-1/">Analysis #1/1</a></p>
]]></content>
  </entry>
  
</feed>
